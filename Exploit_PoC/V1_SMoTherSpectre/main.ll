; ModuleID = 'main.c'
source_filename = "main.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.0, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.0 = type { i64 }
%struct.cpu_set_t = type { [16 x i64] }
%union.pthread_attr_t = type { i64, [48 x i8] }

@secret = dso_local global i32 0, align 4
@zero = dso_local global i32 0, align 4
@crc_attack = dso_local global i64 0, align 8
@crc_victim = dso_local global i64 0, align 8
@mutex = dso_local global %union.pthread_mutex_t zeroinitializer, align 8
@cond = dso_local global %union.pthread_cond_t zeroinitializer, align 8
@memsize = dso_local constant i32 262144, align 4
@.str = private unnamed_addr constant [27 x i8] c"Failed setting threads...\0A\00", align 1
@array = dso_local global [262144 x i8] zeroinitializer, align 512
@memory = dso_local global i8** null, align 8
@dummy = dso_local global i32 0, align 4
@tmp = dso_local global i64 0, align 8
@overall = internal global i64 0, align 8
@.str.1 = private unnamed_addr constant [39 x i8] c"Main thread failed to assign affinity\0A\00", align 1
@.str.2 = private unnamed_addr constant [21 x i8] c"Overall Timing: %ld\0A\00", align 1
@.str.3 = private unnamed_addr constant [27 x i8] c"crc values are %lld, %lld\0A\00", align 1
@x = dso_local global double 0.000000e+00, align 8
@y = dso_local global double 0.000000e+00, align 8
@x2 = dso_local global double 0.000000e+00, align 8
@y2 = dso_local global double 0.000000e+00, align 8

; Function Attrs: noinline nounwind optnone uwtable
define dso_local void @delayloop(i32 %0) #0 {
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  store i32 %0, i32* %2, align 4
  %4 = call i64 @rdtscp()
  %5 = trunc i64 %4 to i32
  store i32 %5, i32* %3, align 4
  br label %6

6:                                                ; preds = %14, %1
  %7 = call i64 @rdtscp()
  %8 = load i32, i32* %3, align 4
  %9 = zext i32 %8 to i64
  %10 = sub i64 %7, %9
  %11 = load i32, i32* %2, align 4
  %12 = sext i32 %11 to i64
  %13 = icmp ult i64 %10, %12
  br i1 %13, label %14, label %15

14:                                               ; preds = %6
  br label %6, !llvm.loop !4

15:                                               ; preds = %6
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i64 @read_pmc(i64 %0) #0 {
  %2 = alloca i64, align 8
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i64 %0, i64* %2, align 8
  store i32 0, i32* %3, align 4
  store i32 0, i32* %4, align 4
  %5 = load i64, i64* %2, align 8
  %6 = call { i32, i32 } asm sideeffect "rdpmc", "={ax},={dx},{cx},~{dirflag},~{fpsr},~{flags}"(i64 %5) #7, !srcloc !6
  %7 = extractvalue { i32, i32 } %6, 0
  %8 = extractvalue { i32, i32 } %6, 1
  store i32 %7, i32* %3, align 4
  store i32 %8, i32* %4, align 4
  %9 = load i32, i32* %4, align 4
  %10 = zext i32 %9 to i64
  %11 = shl i64 %10, 32
  %12 = load i32, i32* %3, align 4
  %13 = zext i32 %12 to i64
  %14 = or i64 %11, %13
  ret i64 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local void @dbuf_init(i8** %0, i32 %1, i32 %2) #0 {
  %4 = alloca i8**, align 8
  %5 = alloca i32, align 4
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  %10 = alloca i8*, align 8
  store i8** %0, i8*** %4, align 8
  store i32 %1, i32* %5, align 4
  store i32 %2, i32* %6, align 4
  store i32 0, i32* %7, align 4
  br label %11

11:                                               ; preds = %25, %3
  %12 = load i32, i32* %7, align 4
  %13 = load i32, i32* %5, align 4
  %14 = icmp slt i32 %12, %13
  br i1 %14, label %15, label %28

15:                                               ; preds = %11
  %16 = load i8**, i8*** %4, align 8
  %17 = load i32, i32* %7, align 4
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds i8*, i8** %16, i64 %18
  %20 = bitcast i8** %19 to i8*
  %21 = load i8**, i8*** %4, align 8
  %22 = load i32, i32* %7, align 4
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i8*, i8** %21, i64 %23
  store i8* %20, i8** %24, align 8
  br label %25

25:                                               ; preds = %15
  %26 = load i32, i32* %7, align 4
  %27 = add nsw i32 %26, 1
  store i32 %27, i32* %7, align 4
  br label %11, !llvm.loop !7

28:                                               ; preds = %11
  %29 = load i32, i32* %5, align 4
  %30 = sub nsw i32 %29, 1
  store i32 %30, i32* %8, align 4
  br label %31

31:                                               ; preds = %78, %28
  %32 = load i32, i32* %8, align 4
  %33 = icmp sgt i32 %32, 0
  br i1 %33, label %34, label %81

34:                                               ; preds = %31
  %35 = load i32, i32* %8, align 4
  %36 = and i32 %35, 511
  %37 = icmp ne i32 %36, 0
  br i1 %37, label %38, label %39

38:                                               ; preds = %34
  br label %78

39:                                               ; preds = %34
  %40 = load i32, i32* %8, align 4
  %41 = load i32, i32* %6, align 4
  %42 = icmp slt i32 %40, %41
  br i1 %42, label %43, label %44

43:                                               ; preds = %39
  br label %78

44:                                               ; preds = %39
  %45 = load i32, i32* %8, align 4
  %46 = load i32, i32* %6, align 4
  %47 = sdiv i32 %45, %46
  %48 = sext i32 %47 to i64
  %49 = call i64 @my_rand(i64 %48)
  %50 = load i32, i32* %6, align 4
  %51 = sext i32 %50 to i64
  %52 = mul i64 %49, %51
  %53 = load i32, i32* %8, align 4
  %54 = load i32, i32* %6, align 4
  %55 = srem i32 %53, %54
  %56 = sext i32 %55 to i64
  %57 = add i64 %52, %56
  %58 = trunc i64 %57 to i32
  store i32 %58, i32* %9, align 4
  %59 = load i8**, i8*** %4, align 8
  %60 = load i32, i32* %8, align 4
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds i8*, i8** %59, i64 %61
  %63 = load i8*, i8** %62, align 8
  store i8* %63, i8** %10, align 8
  %64 = load i8**, i8*** %4, align 8
  %65 = load i32, i32* %9, align 4
  %66 = zext i32 %65 to i64
  %67 = getelementptr inbounds i8*, i8** %64, i64 %66
  %68 = load i8*, i8** %67, align 8
  %69 = load i8**, i8*** %4, align 8
  %70 = load i32, i32* %8, align 4
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i8*, i8** %69, i64 %71
  store i8* %68, i8** %72, align 8
  %73 = load i8*, i8** %10, align 8
  %74 = load i8**, i8*** %4, align 8
  %75 = load i32, i32* %9, align 4
  %76 = zext i32 %75 to i64
  %77 = getelementptr inbounds i8*, i8** %74, i64 %76
  store i8* %73, i8** %77, align 8
  br label %78

78:                                               ; preds = %44, %43, %38
  %79 = load i32, i32* %8, align 4
  %80 = add nsw i32 %79, -1
  store i32 %80, i32* %8, align 4
  br label %31, !llvm.loop !8

81:                                               ; preds = %31
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @my_rand(i64 %0) #0 {
  %2 = alloca i64, align 8
  store i64 %0, i64* %2, align 8
  %3 = call i32 @rand() #7
  %4 = sext i32 %3 to i64
  %5 = shl i64 %4, 48
  %6 = call i32 @rand() #7
  %7 = sext i32 %6 to i64
  %8 = shl i64 %7, 32
  %9 = xor i64 %5, %8
  %10 = call i32 @rand() #7
  %11 = sext i32 %10 to i64
  %12 = shl i64 %11, 16
  %13 = xor i64 %9, %12
  %14 = call i32 @rand() #7
  %15 = sext i32 %14 to i64
  %16 = xor i64 %13, %15
  %17 = load i64, i64* %2, align 8
  %18 = urem i64 %16, %17
  ret i64 %18
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local void @pointer_chase(i8** %0, i32 %1) #0 {
  %3 = alloca i8**, align 8
  %4 = alloca i32, align 4
  %5 = alloca i8**, align 8
  store i8** %0, i8*** %3, align 8
  store i32 %1, i32* %4, align 4
  %6 = load i8**, i8*** %3, align 8
  store i8** %6, i8*** %5, align 8
  br label %7

7:                                                ; preds = %11, %2
  %8 = load i32, i32* %4, align 4
  %9 = add nsw i32 %8, -1
  store i32 %9, i32* %4, align 4
  %10 = icmp sgt i32 %8, 0
  br i1 %10, label %11, label %15

11:                                               ; preds = %7
  %12 = load i8**, i8*** %5, align 8
  %13 = load i8*, i8** %12, align 8
  %14 = bitcast i8* %13 to i8**
  store i8** %14, i8*** %5, align 8
  br label %7, !llvm.loop !9

15:                                               ; preds = %7
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i8* @victim() #0 {
  %1 = alloca i8*, align 8
  %2 = alloca %struct.cpu_set_t, align 8
  %3 = alloca %struct.cpu_set_t, align 8
  %4 = alloca i64, align 8
  %5 = alloca i64, align 8
  %6 = alloca i64, align 8
  %7 = alloca i32, align 4
  br label %8

8:                                                ; preds = %0
  %9 = bitcast %struct.cpu_set_t* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %9, i8 0, i64 128, i1 false)
  br label %10

10:                                               ; preds = %8
  br label %11

11:                                               ; preds = %10
  %12 = bitcast %struct.cpu_set_t* %3 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %12, i8 0, i64 128, i1 false)
  br label %13

13:                                               ; preds = %11
  store i64 1, i64* %4, align 8
  %14 = load i64, i64* %4, align 8
  %15 = udiv i64 %14, 8
  %16 = icmp ult i64 %15, 128
  br i1 %16, label %17, label %28

17:                                               ; preds = %13
  %18 = load i64, i64* %4, align 8
  %19 = urem i64 %18, 64
  %20 = shl i64 1, %19
  %21 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %2, i32 0, i32 0
  %22 = getelementptr inbounds [16 x i64], [16 x i64]* %21, i64 0, i64 0
  %23 = load i64, i64* %4, align 8
  %24 = udiv i64 %23, 64
  %25 = getelementptr inbounds i64, i64* %22, i64 %24
  %26 = load i64, i64* %25, align 8
  %27 = or i64 %26, %20
  store i64 %27, i64* %25, align 8
  br label %29

28:                                               ; preds = %13
  br label %29

29:                                               ; preds = %28, %17
  %30 = phi i64 [ %27, %17 ], [ 0, %28 ]
  store i64 %30, i64* %5, align 8
  %31 = load i64, i64* %5, align 8
  %32 = call i64 @pthread_self() #8
  %33 = call i32 @pthread_setaffinity_np(i64 %32, i64 128, %struct.cpu_set_t* %2) #7
  %34 = icmp slt i32 %33, 0
  br i1 %34, label %61, label %35

35:                                               ; preds = %29
  %36 = call i64 @pthread_self() #8
  %37 = call i32 @pthread_getaffinity_np(i64 %36, i64 128, %struct.cpu_set_t* %3) #7
  %38 = icmp ne i32 %37, 0
  br i1 %38, label %61, label %39

39:                                               ; preds = %35
  store i64 1, i64* %6, align 8
  %40 = load i64, i64* %6, align 8
  %41 = udiv i64 %40, 8
  %42 = icmp ult i64 %41, 128
  br i1 %42, label %43, label %56

43:                                               ; preds = %39
  %44 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %3, i32 0, i32 0
  %45 = getelementptr inbounds [16 x i64], [16 x i64]* %44, i64 0, i64 0
  %46 = load i64, i64* %6, align 8
  %47 = udiv i64 %46, 64
  %48 = getelementptr inbounds i64, i64* %45, i64 %47
  %49 = load i64, i64* %48, align 8
  %50 = load i64, i64* %6, align 8
  %51 = urem i64 %50, 64
  %52 = shl i64 1, %51
  %53 = and i64 %49, %52
  %54 = icmp ne i64 %53, 0
  %55 = zext i1 %54 to i32
  br label %57

56:                                               ; preds = %39
  br label %57

57:                                               ; preds = %56, %43
  %58 = phi i32 [ %55, %43 ], [ 0, %56 ]
  store i32 %58, i32* %7, align 4
  %59 = load i32, i32* %7, align 4
  %60 = icmp ne i32 %59, 0
  br i1 %60, label %63, label %61

61:                                               ; preds = %57, %35, %29
  %62 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str, i64 0, i64 0))
  call void @exit(i32 0) #9
  unreachable

63:                                               ; preds = %57
  call void @victim_function_new(i32 0, i32 1)
  call void @victim_function_new(i32 0, i32 1)
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !10
  call void asm sideeffect "clflush 0($0)", "r,~{dirflag},~{fpsr},~{flags}"(i8* getelementptr inbounds ([262144 x i8], [262144 x i8]* @array, i64 0, i64 2048)) #7, !srcloc !11
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !12
  %64 = load i8**, i8*** @memory, align 8
  call void @pointer_chase(i8** %64, i32 100)
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !13
  %65 = load i32, i32* @secret, align 4
  call void @victim_function_new(i32 %65, i32 100)
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !14
  %66 = load i8*, i8** %1, align 8
  ret i8* %66
}

; Function Attrs: argmemonly nofree nounwind willreturn writeonly
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind
declare dso_local i32 @pthread_setaffinity_np(i64, i64, %struct.cpu_set_t*) #2

; Function Attrs: nounwind readnone willreturn
declare dso_local i64 @pthread_self() #3

; Function Attrs: nounwind
declare dso_local i32 @pthread_getaffinity_np(i64, i64, %struct.cpu_set_t*) #2

declare dso_local i32 @printf(i8*, ...) #4

; Function Attrs: noreturn nounwind
declare dso_local void @exit(i32) #5

; Function Attrs: noinline nounwind optnone uwtable
define internal void @victim_function_new(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  %6 = alloca i64, align 8
  %7 = alloca i64, align 8
  %8 = alloca i64, align 8
  %9 = alloca i64, align 8
  %10 = alloca i64, align 8
  %11 = alloca i64, align 8
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  store volatile i32 0, i32* %5, align 4
  br label %12

12:                                               ; preds = %16, %2
  %13 = load volatile i32, i32* %5, align 4
  %14 = icmp slt i32 %13, 200
  br i1 %14, label %15, label %19

15:                                               ; preds = %12
  br label %16

16:                                               ; preds = %15
  %17 = load volatile i32, i32* %5, align 4
  %18 = add nsw i32 %17, 1
  store volatile i32 %18, i32* %5, align 4
  br label %12, !llvm.loop !15

19:                                               ; preds = %12
  %20 = load i32, i32* %4, align 4
  %21 = load i8, i8* getelementptr inbounds ([262144 x i8], [262144 x i8]* @array, i64 0, i64 2048), align 512
  %22 = zext i8 %21 to i32
  %23 = icmp slt i32 %20, %22
  br i1 %23, label %24, label %180

24:                                               ; preds = %19
  %25 = load i32, i32* %3, align 4
  %26 = icmp eq i32 %25, 0
  br i1 %26, label %27, label %103

27:                                               ; preds = %24
  %28 = load i64, i64* %6, align 8
  %29 = load i64, i64* %7, align 8
  %30 = load i64, i64* %8, align 8
  %31 = load i64, i64* %9, align 8
  %32 = load i64, i64* %10, align 8

%33 = or i64 %28, %29
%34 = or i64 %29, %30
%35 = or i64 %30, %31
%36 = or i64 %31, %32
%37 = or i64 %32, %33
%38 = or i64 %33, %34
%39 = or i64 %34, %35
%40 = or i64 %35, %36
%41 = or i64 %36, %37
%42 = or i64 %37, %38
%43 = or i64 %38, %39
%44 = or i64 %39, %40
%45 = or i64 %40, %41
%46 = or i64 %41, %42
%47 = or i64 %42, %43
%48 = or i64 %43, %44
%49 = or i64 %44, %45
%50 = or i64 %45, %46
%51 = or i64 %46, %47
%52 = or i64 %47, %48
%53 = or i64 %48, %49
%54 = or i64 %49, %50
%55 = or i64 %50, %51
%56 = or i64 %51, %52
%57 = or i64 %52, %53
%58 = or i64 %53, %54
%59 = or i64 %54, %55
%60 = or i64 %55, %56
%61 = or i64 %56, %57
%62 = or i64 %57, %58
%63 = or i64 %58, %59
%64 = or i64 %59, %60
%65 = or i64 %60, %61
%66 = or i64 %61, %62
%67 = or i64 %62, %63
%68 = or i64 %63, %64
%69 = or i64 %64, %65
%70 = or i64 %65, %66
%71 = or i64 %66, %67
%72 = or i64 %67, %68
%73 = or i64 %68, %69
%74 = or i64 %69, %70
%75 = or i64 %70, %71
%76 = or i64 %71, %72
%77 = or i64 %72, %73
%78 = or i64 %73, %74
%79 = or i64 %74, %75
%80 = or i64 %75, %76
%81 = or i64 %76, %77
%82 = or i64 %77, %78
%83 = or i64 %78, %79
%84 = or i64 %79, %80
%85 = or i64 %80, %81
%86 = or i64 %81, %82
%87 = or i64 %82, %83
%88 = or i64 %83, %84
%89 = or i64 %84, %85
%90 = or i64 %85, %86
%91 = or i64 %86, %87
%92 = or i64 %87, %88
%93 = or i64 %88, %89
%94 = or i64 %89, %90
%95 = or i64 %90, %91
%96 = or i64 %91, %92
%97 = or i64 %92, %93
%98 = or i64 %93, %94
%99 = or i64 %94, %95
%100 = or i64 %95, %96
%101 = or i64 %96, %97
%102 = or i64 %97, %98

  store i64 %98, i64* %10, align 8
  store i64 %99, i64* %9, align 8
  store i64 %100, i64* %8, align 8
  store i64 %101, i64* %7, align 8
  store i64 %102, i64* %6, align 8
  br label %179

103:                                              ; preds = %24
  %104 = load i64, i64* %6, align 8
  %105 = load i64, i64* %7, align 8
  %106 = load i64, i64* %8, align 8
  %107 = load i64, i64* %9, align 8
  %108 = load i64, i64* %10, align 8

%109 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %104, i64 %104)
%110 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %105, i64 %105)
%111 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %106, i64 %106)
%112 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %107, i64 %107)
%113 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %108, i64 %108)
%114 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %109, i64 %109)
%115 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %110, i64 %110)
%116 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %111, i64 %111)
%117 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %112, i64 %112)
%118 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %113, i64 %113)
%119 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %114, i64 %114)
%120 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %115, i64 %115)
%121 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %116, i64 %116)
%122 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %117, i64 %117)
%123 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %118, i64 %118)
%124 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %119, i64 %119)
%125 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %120, i64 %120)
%126 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %121, i64 %121)
%127 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %122, i64 %122)
%128 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %123, i64 %123)
%129 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %124, i64 %124)
%130 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %125, i64 %125)
%131 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %126, i64 %126)
%132 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %127, i64 %127)
%133 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %128, i64 %128)
%134 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %129, i64 %129)
%135 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %130, i64 %130)
%136 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %131, i64 %131)
%137 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %132, i64 %132)
%138 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %133, i64 %133)
%139 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %134, i64 %134)
%140 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %135, i64 %135)
%141 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %136, i64 %136)
%142 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %137, i64 %137)
%143 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %138, i64 %138)
%144 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %139, i64 %139)
%145 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %140, i64 %140)
%146 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %141, i64 %141)
%147 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %142, i64 %142)
%148 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %143, i64 %143)
%149 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %144, i64 %144)
%150 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %145, i64 %145)
%151 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %146, i64 %146)
%152 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %147, i64 %147)
%153 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %148, i64 %148)
%154 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %149, i64 %149)
%155 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %150, i64 %150)
%156 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %151, i64 %151)
%157 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %152, i64 %152)
%158 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %153, i64 %153)
%159 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %154, i64 %154)
%160 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %155, i64 %155)
%161 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %156, i64 %156)
%162 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %157, i64 %157)
%163 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %158, i64 %158)
%164 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %159, i64 %159)
%165 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %160, i64 %160)
%166 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %161, i64 %161)
%167 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %162, i64 %162)
%168 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %163, i64 %163)
%169 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %164, i64 %164)
%170 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %165, i64 %165)
%171 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %166, i64 %166)
%172 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %167, i64 %167)
%173 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %168, i64 %168)
%174 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %169, i64 %169)
%175 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %170, i64 %170)
%176 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %171, i64 %171)
%177 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %172, i64 %172)
%178 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %173, i64 %173)

  store i64 %174, i64* %6, align 8
  store i64 %175, i64* %7, align 8
  store i64 %176, i64* %8, align 8
  store i64 %177, i64* %9, align 8
  store i64 %178, i64* %10, align 8
  br label %179

179:                                              ; preds = %238, %27
  br label %180

180:                                              ; preds = %179, %19
  %181 = load i64, i64* %6, align 8
  %182 = load i64, i64* %7, align 8
  %183 = load i64, i64* %8, align 8
  %184 = load i64, i64* %9, align 8
  %185 = load i64, i64* %10, align 8

  %186 = add i64 %181, %182
  %187 = add i64 %186, %183
  %188 = add i64 %187, %184
  %189 = add i64 %188, %185
  %190 = load i64, i64* @crc_victim, align 8
  %191 = add i64 %190, %189
  store i64 %191, i64* @crc_victim, align 8
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i8* @attack() #0 {
  %1 = alloca i32*, align 8
  %2 = alloca i32*, align 8
  %3 = alloca i8*, align 8
  %4 = alloca %struct.cpu_set_t, align 8
  %5 = alloca %struct.cpu_set_t, align 8
  %6 = alloca i64, align 8
  %7 = alloca i64, align 8
  %8 = alloca i64, align 8
  %9 = alloca i32, align 4
  %10 = alloca i64, align 8
  %11 = alloca i64, align 8
  %12 = alloca i64, align 8
  %13 = alloca i64, align 8
  %14 = alloca i64, align 8
  %15 = alloca i64, align 8
  %16 = alloca i32, align 4
  br label %17

17:                                               ; preds = %0
  %18 = bitcast %struct.cpu_set_t* %4 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %18, i8 0, i64 128, i1 false)
  br label %19

19:                                               ; preds = %17
  br label %20

20:                                               ; preds = %19
  %21 = bitcast %struct.cpu_set_t* %5 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %21, i8 0, i64 128, i1 false)
  br label %22

22:                                               ; preds = %20
  store i64 5, i64* %6, align 8
  %23 = load i64, i64* %6, align 8
  %24 = udiv i64 %23, 8
  %25 = icmp ult i64 %24, 128
  br i1 %25, label %26, label %37

26:                                               ; preds = %22
  %27 = load i64, i64* %6, align 8
  %28 = urem i64 %27, 64
  %29 = shl i64 1, %28
  %30 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %4, i32 0, i32 0
  %31 = getelementptr inbounds [16 x i64], [16 x i64]* %30, i64 0, i64 0
  %32 = load i64, i64* %6, align 8
  %33 = udiv i64 %32, 64
  %34 = getelementptr inbounds i64, i64* %31, i64 %33
  %35 = load i64, i64* %34, align 8
  %36 = or i64 %35, %29
  store i64 %36, i64* %34, align 8
  br label %38

37:                                               ; preds = %22
  br label %38

38:                                               ; preds = %37, %26
  %39 = phi i64 [ %36, %26 ], [ 0, %37 ]
  store i64 %39, i64* %7, align 8
  %40 = load i64, i64* %7, align 8
  %41 = call i64 @pthread_self() #8
  %42 = call i32 @pthread_setaffinity_np(i64 %41, i64 128, %struct.cpu_set_t* %4) #7
  %43 = icmp slt i32 %42, 0
  br i1 %43, label %70, label %44

44:                                               ; preds = %38
  %45 = call i64 @pthread_self() #8
  %46 = call i32 @pthread_getaffinity_np(i64 %45, i64 128, %struct.cpu_set_t* %5) #7
  %47 = icmp ne i32 %46, 0
  br i1 %47, label %70, label %48

48:                                               ; preds = %44
  store i64 5, i64* %8, align 8
  %49 = load i64, i64* %8, align 8
  %50 = udiv i64 %49, 8
  %51 = icmp ult i64 %50, 128
  br i1 %51, label %52, label %65

52:                                               ; preds = %48
  %53 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %5, i32 0, i32 0
  %54 = getelementptr inbounds [16 x i64], [16 x i64]* %53, i64 0, i64 0
  %55 = load i64, i64* %8, align 8
  %56 = udiv i64 %55, 64
  %57 = getelementptr inbounds i64, i64* %54, i64 %56
  %58 = load i64, i64* %57, align 8
  %59 = load i64, i64* %8, align 8
  %60 = urem i64 %59, 64
  %61 = shl i64 1, %60
  %62 = and i64 %58, %61
  %63 = icmp ne i64 %62, 0
  %64 = zext i1 %63 to i32
  br label %66

65:                                               ; preds = %48
  br label %66

66:                                               ; preds = %65, %52
  %67 = phi i32 [ %64, %52 ], [ 0, %65 ]
  store i32 %67, i32* %9, align 4
  %68 = load i32, i32* %9, align 4
  %69 = icmp ne i32 %68, 0
  br i1 %69, label %72, label %70

70:                                               ; preds = %66, %44, %38
  %71 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str, i64 0, i64 0))
  call void @exit(i32 0) #9
  unreachable

72:                                               ; preds = %66
  call void @loop_function(i8 zeroext 0, i32 1)
  call void @loop_function(i8 zeroext 0, i32 1)
  %73 = load i8**, i8*** @memory, align 8
  call void @pointer_chase(i8** %73, i32 100)
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !16
  store volatile i32 0, i32* %16, align 4
  br label %74

74:                                               ; preds = %78, %72
  %75 = load volatile i32, i32* %16, align 4
  %76 = icmp slt i32 %75, 200
  br i1 %76, label %77, label %81

77:                                               ; preds = %74
  br label %78

78:                                               ; preds = %77
  %79 = load volatile i32, i32* %16, align 4
  %80 = add nsw i32 %79, 1
  store volatile i32 %80, i32* %16, align 4
  br label %74, !llvm.loop !17

81:                                               ; preds = %74
  store i32* @dummy, i32** %1, align 8
  %82 = load i32*, i32** %1, align 8
  %83 = call { i64, i32 } @llvm.x86.rdtscp() #7
  %84 = extractvalue { i64, i32 } %83, 1
  store i32 %84, i32* %82, align 4
  %85 = extractvalue { i64, i32 } %83, 0
  store i64 %85, i64* @tmp, align 8
  %86 = load i64, i64* %10, align 8
  %87 = load i64, i64* %11, align 8
  %88 = load i64, i64* %12, align 8
  %89 = load i64, i64* %13, align 8
  %90 = load i64, i64* %14, align 8
  
%91 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %86, i64 %86)
%92 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %87, i64 %87)
%93 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %88, i64 %88)
%94 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %89, i64 %89)
%95 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %90, i64 %90)
%96 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %91, i64 %91)
%97 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %92, i64 %92)
%98 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %93, i64 %93)
%99 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %94, i64 %94)
%100 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %95, i64 %95)
%101 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %96, i64 %96)
%102 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %97, i64 %97)
%103 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %98, i64 %98)
%104 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %99, i64 %99)
%105 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %100, i64 %100)
%106 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %101, i64 %101)
%107 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %102, i64 %102)
%108 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %103, i64 %103)
%109 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %104, i64 %104)
%110 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %105, i64 %105)
%111 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %106, i64 %106)
%112 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %107, i64 %107)
%113 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %108, i64 %108)
%114 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %109, i64 %109)
%115 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %110, i64 %110)
%116 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %111, i64 %111)
%117 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %112, i64 %112)
%118 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %113, i64 %113)
%119 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %114, i64 %114)
%120 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %115, i64 %115)
%121 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %116, i64 %116)
%122 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %117, i64 %117)
%123 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %118, i64 %118)
%124 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %119, i64 %119)
%125 = call i64 @llvm.x86.sse42.crc32.64.64(i64 %120, i64 %120)





  store i64 %125, i64* %14, align 8
  store i32* @dummy, i32** %2, align 8
  %126 = load i32*, i32** %2, align 8
  %127 = call { i64, i32 } @llvm.x86.rdtscp() #7
  %128 = extractvalue { i64, i32 } %127, 1
  store i32 %128, i32* %126, align 4
  %129 = extractvalue { i64, i32 } %127, 0
  %130 = load i64, i64* @tmp, align 8
  %131 = sub i64 %129, %130
  store i64 %131, i64* @tmp, align 8
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !18
  %132 = load i64, i64* @tmp, align 8
  %133 = load i64, i64* @overall, align 8
  %134 = add i64 %133, %132
  store i64 %134, i64* @overall, align 8
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !19
  %135 = add i64 %121, %122
  %136 = add i64 %135, %123
  %137 = add i64 %136, %124
  %138 = add i64 %137, %125
  %139 = load i64, i64* @crc_attack, align 8
  %140 = add i64 %139, %138

  store i64 %140, i64* @crc_attack, align 8
  %141 = load i8*, i8** %3, align 8
  ret i8* %141
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @loop_function(i8 zeroext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  store volatile i32 0, i32* %5, align 4
  br label %6

6:                                                ; preds = %10, %2
  %7 = load volatile i32, i32* %5, align 4
  %8 = icmp slt i32 %7, 200
  br i1 %8, label %9, label %13

9:                                                ; preds = %6
  br label %10

10:                                               ; preds = %9
  %11 = load volatile i32, i32* %5, align 4
  %12 = add nsw i32 %11, 1
  store volatile i32 %12, i32* %5, align 4
  br label %6, !llvm.loop !20

13:                                               ; preds = %6
  ret void
}

; Function Attrs: nounwind readnone
declare i64 @llvm.x86.sse42.crc32.64.64(i64, i64) #6

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i64, align 8
  %5 = alloca i64, align 8
  %6 = alloca %struct.cpu_set_t, align 8
  %7 = alloca %struct.cpu_set_t, align 8
  %8 = alloca i64, align 8
  %9 = alloca i64, align 8
  %10 = alloca i64, align 8
  %11 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 0, i32* %2, align 4
  br label %12

12:                                               ; preds = %94, %0
  %13 = load i32, i32* %2, align 4
  %14 = icmp slt i32 %13, 10
  br i1 %14, label %15, label %97

15:                                               ; preds = %12
  %16 = load i32, i32* %2, align 4
  %17 = srem i32 %16, 2
  store i32 %17, i32* @secret, align 4
  store i64 0, i64* @overall, align 8
  store i32 0, i32* %3, align 4
  br label %18

18:                                               ; preds = %87, %15
  %19 = load i32, i32* %3, align 4
  %20 = icmp slt i32 %19, 100
  br i1 %20, label %21, label %90

21:                                               ; preds = %18
  %22 = call noalias i8* @valloc(i64 262144) #7
  %23 = bitcast i8* %22 to i8**
  store i8** %23, i8*** @memory, align 8
  %24 = load i8**, i8*** @memory, align 8
  call void @dbuf_init(i8** %24, i32 32768, i32 1024)
  store i8 10, i8* getelementptr inbounds ([262144 x i8], [262144 x i8]* @array, i64 0, i64 2048), align 512
  br label %25

25:                                               ; preds = %21
  %26 = bitcast %struct.cpu_set_t* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %26, i8 0, i64 128, i1 false)
  br label %27

27:                                               ; preds = %25
  br label %28

28:                                               ; preds = %27
  %29 = bitcast %struct.cpu_set_t* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %29, i8 0, i64 128, i1 false)
  br label %30

30:                                               ; preds = %28
  store i64 2, i64* %8, align 8
  %31 = load i64, i64* %8, align 8
  %32 = udiv i64 %31, 8
  %33 = icmp ult i64 %32, 128
  br i1 %33, label %34, label %45

34:                                               ; preds = %30
  %35 = load i64, i64* %8, align 8
  %36 = urem i64 %35, 64
  %37 = shl i64 1, %36
  %38 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %6, i32 0, i32 0
  %39 = getelementptr inbounds [16 x i64], [16 x i64]* %38, i64 0, i64 0
  %40 = load i64, i64* %8, align 8
  %41 = udiv i64 %40, 64
  %42 = getelementptr inbounds i64, i64* %39, i64 %41
  %43 = load i64, i64* %42, align 8
  %44 = or i64 %43, %37
  store i64 %44, i64* %42, align 8
  br label %46

45:                                               ; preds = %30
  br label %46

46:                                               ; preds = %45, %34
  %47 = phi i64 [ %44, %34 ], [ 0, %45 ]
  store i64 %47, i64* %9, align 8
  %48 = load i64, i64* %9, align 8
  %49 = call i32 @sched_setaffinity(i32 0, i64 128, %struct.cpu_set_t* %6) #7
  %50 = icmp slt i32 %49, 0
  br i1 %50, label %76, label %51

51:                                               ; preds = %46
  %52 = call i32 @sched_getaffinity(i32 0, i64 128, %struct.cpu_set_t* %7) #7
  %53 = icmp ne i32 %52, 0
  br i1 %53, label %76, label %54

54:                                               ; preds = %51
  store i64 2, i64* %10, align 8
  %55 = load i64, i64* %10, align 8
  %56 = udiv i64 %55, 8
  %57 = icmp ult i64 %56, 128
  br i1 %57, label %58, label %71

58:                                               ; preds = %54
  %59 = getelementptr inbounds %struct.cpu_set_t, %struct.cpu_set_t* %7, i32 0, i32 0
  %60 = getelementptr inbounds [16 x i64], [16 x i64]* %59, i64 0, i64 0
  %61 = load i64, i64* %10, align 8
  %62 = udiv i64 %61, 64
  %63 = getelementptr inbounds i64, i64* %60, i64 %62
  %64 = load i64, i64* %63, align 8
  %65 = load i64, i64* %10, align 8
  %66 = urem i64 %65, 64
  %67 = shl i64 1, %66
  %68 = and i64 %64, %67
  %69 = icmp ne i64 %68, 0
  %70 = zext i1 %69 to i32
  br label %72

71:                                               ; preds = %54
  br label %72

72:                                               ; preds = %71, %58
  %73 = phi i32 [ %70, %58 ], [ 0, %71 ]
  store i32 %73, i32* %11, align 4
  %74 = load i32, i32* %11, align 4
  %75 = icmp ne i32 %74, 0
  br i1 %75, label %78, label %76

76:                                               ; preds = %72, %51, %46
  %77 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.1, i64 0, i64 0))
  call void @exit(i32 0) #9
  unreachable

78:                                               ; preds = %72
  %79 = call i32 @pthread_create(i64* %4, %union.pthread_attr_t* null, i8* (i8*)* bitcast (i8* ()* @victim to i8* (i8*)*), i8* null) #7
  %80 = call i32 @pthread_create(i64* %5, %union.pthread_attr_t* null, i8* (i8*)* bitcast (i8* ()* @attack to i8* (i8*)*), i8* null) #7
  %81 = load i64, i64* %4, align 8
  %82 = call i32 @pthread_join(i64 %81, i8** null)
  %83 = load i64, i64* %5, align 8
  %84 = call i32 @pthread_join(i64 %83, i8** null)
  %85 = load i8**, i8*** @memory, align 8
  %86 = bitcast i8** %85 to i8*
  call void @free(i8* %86) #7
  br label %87

87:                                               ; preds = %78
  %88 = load i32, i32* %3, align 4
  %89 = add nsw i32 %88, 1
  store i32 %89, i32* %3, align 4
  br label %18, !llvm.loop !21

90:                                               ; preds = %18
  %91 = load i64, i64* @overall, align 8
  %92 = udiv i64 %91, 100
  %93 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.2, i64 0, i64 0), i64 %92)
  br label %94

94:                                               ; preds = %90
  %95 = load i32, i32* %2, align 4
  %96 = add nsw i32 %95, 1
  store i32 %96, i32* %2, align 4
  br label %12, !llvm.loop !22

97:                                               ; preds = %12
  call void asm sideeffect "lfence;\0Amfence;\0Asfence", "~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !23
  %98 = load i64, i64* @crc_attack, align 8
  %99 = load i64, i64* @crc_victim, align 8
  %100 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.3, i64 0, i64 0), i64 %98, i64 %99)
  ret i32 0
}

; Function Attrs: nounwind
declare dso_local noalias i8* @valloc(i64) #2

; Function Attrs: nounwind
declare dso_local i32 @sched_setaffinity(i32, i64, %struct.cpu_set_t*) #2

; Function Attrs: nounwind
declare dso_local i32 @sched_getaffinity(i32, i64, %struct.cpu_set_t*) #2

; Function Attrs: nounwind
declare dso_local i32 @pthread_create(i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*) #2

declare dso_local i32 @pthread_join(i64, i8**) #4

; Function Attrs: nounwind
declare dso_local void @free(i8*) #2

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @rdtscp() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = call { i32, i32 } asm sideeffect "rdtscp", "={ax},={dx},~{dirflag},~{fpsr},~{flags}"() #7, !srcloc !24
  %4 = extractvalue { i32, i32 } %3, 0
  %5 = extractvalue { i32, i32 } %3, 1
  store i32 %4, i32* %1, align 4
  store i32 %5, i32* %2, align 4
  %6 = load i32, i32* %1, align 4
  %7 = zext i32 %6 to i64
  %8 = load i32, i32* %2, align 4
  %9 = zext i32 %8 to i64
  %10 = shl i64 %9, 32
  %11 = or i64 %7, %10
  ret i64 %11
}

; Function Attrs: nounwind
declare dso_local i32 @rand() #2

; Function Attrs: nounwind
declare { i64, i32 } @llvm.x86.rdtscp() #7

attributes #0 = { noinline nounwind optnone uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87" "tune-cpu"="generic" }
attributes #1 = { argmemonly nofree nounwind willreturn writeonly }
attributes #2 = { nounwind "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87" "tune-cpu"="generic" }
attributes #3 = { nounwind readnone willreturn "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87" "tune-cpu"="generic" }
attributes #4 = { "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87" "tune-cpu"="generic" }
attributes #5 = { noreturn nounwind "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87" "tune-cpu"="generic" }
attributes #6 = { nounwind readnone }
attributes #7 = { nounwind }
attributes #8 = { nounwind readnone willreturn }
attributes #9 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"uwtable", i32 1}
!2 = !{i32 7, !"frame-pointer", i32 2}
!3 = !{!"clang version 14.0.0 (https://github.com/llvm/llvm-project.git 14500628b6b6c6cbe6dd3c0e116674124b3c25fd)"}
!4 = distinct !{!4, !5}
!5 = !{!"llvm.loop.mustprogress"}
!6 = !{i64 3243250}
!7 = distinct !{!7, !5}
!8 = distinct !{!8, !5}
!9 = distinct !{!9, !5}
!10 = !{i64 2150732926, i64 2150732936, i64 2150732945}
!11 = !{i64 2150732981}
!12 = !{i64 2150733051, i64 2150733061, i64 2150733070}
!13 = !{i64 2150733100, i64 2150733110, i64 2150733119}
!14 = !{i64 2150733143, i64 2150733153, i64 2150733162}
!15 = distinct !{!15, !5}
!16 = !{i64 2150734377, i64 2150734387, i64 2150734396}
!17 = distinct !{!17, !5}
!18 = !{i64 2150734420, i64 2150734430, i64 2150734439}
!19 = !{i64 2150734463, i64 2150734473, i64 2150734482}
!20 = distinct !{!20, !5}
!21 = distinct !{!21, !5}
!22 = distinct !{!22, !5}
!23 = !{i64 2150735772, i64 2150735782, i64 2150735791}
!24 = !{i64 3242553}
